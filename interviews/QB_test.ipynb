{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QB_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-qcwXU1CUIX"
      },
      "source": [
        "#### TestQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0twJMkxN_Jc"
      },
      "source": [
        "#!/bin/python3\n",
        "\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def calcMissing(readings):\n",
        "    \"\"\"\n",
        "    Compute Mercury Levels for missing rows in input data.\n",
        "    \"\"\"\n",
        "    # Read data\n",
        "    data, index, missing_idx = [], [], []\n",
        "    for i, r in enumerate(readings):\n",
        "        seq = r.split(\" \")\n",
        "        date, time, level = seq[0], seq[1], seq[-1]\n",
        "        date = \" \".join([date, time])\n",
        "\n",
        "        #seq = r.split(\"\\t\")\n",
        "        #date, level = seq\n",
        "\n",
        "        index.append(date)\n",
        "        # Remember indices of missing values\n",
        "        if level.startswith(\"Missing\"):\n",
        "            missing_idx.append(i)\n",
        "            level = pd.NA\n",
        "        else:\n",
        "            level = float(level)\n",
        "\n",
        "        data.append(level)\n",
        "\n",
        "    # Set-up pandas dataframe\n",
        "    df = pd.DataFrame(data, index=index, columns=[\"level\"])\n",
        "    df[\"level\"] = pd.to_numeric(df[\"level\"], errors='coerce')\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "\n",
        "    # Fill NA simplistic via backfill: Passes 7/10 cases\n",
        "    #df = df.fillna(value=None, method='backfill', axis=None, limit=None, downcast=None)\n",
        "    # Fill NA via interpolation: \n",
        "    df = df.interpolate(method='time', limit_direction=\"both\")\n",
        "\n",
        "    # Return\n",
        "    out = \"\\n\".join([str(df.iloc[x].item()) for x in missing_idx])\n",
        "\n",
        "    print(out)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_FsTE7PRtR5"
      },
      "source": [
        "DATA = \"\"\"\n",
        "1/3/2012 16:00:00   Missing_1\n",
        "1/4/2012 16:00:00   27.47\n",
        "1/5/2012 16:00:00   27.728\n",
        "1/6/2012 16:00:00   28.19\n",
        "1/9/2012 16:00:00   28.1\n",
        "1/10/2012 16:00:00  28.15\n",
        "12/13/2012 16:00:00 27.52\n",
        "12/14/2012 16:00:00 Missing_19\n",
        "12/17/2012 16:00:00 27.215\n",
        "12/18/2012 16:00:00 27.63\n",
        "12/19/2012 16:00:00 27.73\n",
        "12/20/2012 16:00:00 Missing_20\n",
        "12/21/2012 16:00:00 27.49\n",
        "12/24/2012 13:00:00 27.25\n",
        "12/26/2012 16:00:00 27.2\n",
        "12/27/2012 16:00:00 27.09\n",
        "12/28/2012 16:00:00 26.9\n",
        "12/31/2012 16:00:00 26.77\n",
        "\"\"\""
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5jA-srORsqt",
        "outputId": "76420cb1-3962-437f-da7a-fa9fece7b17a"
      },
      "source": [
        "readings = (DATA.split(\"\\n\")[1:-1])\n",
        "df = calcMissing(readings)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.47\n",
            "27.44375\n",
            "27.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "DqSzJ6CWVswx",
        "outputId": "27269471-4c00-439b-e7d9-41ddc639c5a4"
      },
      "source": [
        "df"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-01-03 16:00:00</th>\n",
              "      <td>27.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-04 16:00:00</th>\n",
              "      <td>27.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-05 16:00:00</th>\n",
              "      <td>27.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-06 16:00:00</th>\n",
              "      <td>28.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-09 16:00:00</th>\n",
              "      <td>28.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-01-10 16:00:00</th>\n",
              "      <td>28.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-13 16:00:00</th>\n",
              "      <td>27.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-14 16:00:00</th>\n",
              "      <td>27.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-17 16:00:00</th>\n",
              "      <td>27.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-18 16:00:00</th>\n",
              "      <td>27.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-19 16:00:00</th>\n",
              "      <td>27.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-20 16:00:00</th>\n",
              "      <td>27.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-21 16:00:00</th>\n",
              "      <td>27.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-24 13:00:00</th>\n",
              "      <td>27.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-26 16:00:00</th>\n",
              "      <td>27.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-27 16:00:00</th>\n",
              "      <td>27.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-28 16:00:00</th>\n",
              "      <td>26.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-12-31 16:00:00</th>\n",
              "      <td>26.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     level\n",
              "2012-01-03 16:00:00  27.47\n",
              "2012-01-04 16:00:00  27.47\n",
              "2012-01-05 16:00:00  27.73\n",
              "2012-01-06 16:00:00  28.19\n",
              "2012-01-09 16:00:00  28.10\n",
              "2012-01-10 16:00:00  28.15\n",
              "2012-12-13 16:00:00  27.52\n",
              "2012-12-14 16:00:00  27.44\n",
              "2012-12-17 16:00:00  27.21\n",
              "2012-12-18 16:00:00  27.63\n",
              "2012-12-19 16:00:00  27.73\n",
              "2012-12-20 16:00:00  27.61\n",
              "2012-12-21 16:00:00  27.49\n",
              "2012-12-24 13:00:00  27.25\n",
              "2012-12-26 16:00:00  27.20\n",
              "2012-12-27 16:00:00  27.09\n",
              "2012-12-28 16:00:00  26.90\n",
              "2012-12-31 16:00:00  26.77"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9xbJxP1CSgk"
      },
      "source": [
        "#### QB Q1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG5sKc8nZcU-",
        "outputId": "8a44517c-862d-43b4-fbeb-03b806e5c929"
      },
      "source": [
        "#!/bin/python3\n",
        "\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "\n",
        "\n",
        "# Complete the 'efficientJanitor' function below.\n",
        "#\n",
        "# The function is expected to return an INTEGER.\n",
        "# The function accepts FLOAT_ARRAY weight as parameter.\n",
        "#\n",
        "\n",
        "def efficientJanitor(weight):\n",
        "    \"\"\"\n",
        "    Find minimum num of ways to combine each weight to sum up to 3.\n",
        "\n",
        "    Args:\n",
        "      weight: List of weights of bags\n",
        "    \n",
        "    Returns:\n",
        "      int: Number of trips required to bring bags outside\n",
        "\n",
        "    Example:\n",
        "      Input:\n",
        "      n = 5\n",
        "      weight = [1.01, 1.99, 2.5, 1.5, 1.01]\n",
        "      \n",
        "      Output:\n",
        "      3 (since [1.01 + 1.99, 2.5, 1.5+1.01])\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    i, j = 0, len(weight) - 1\n",
        "    weight.sort()\n",
        "    # Iterate through weights\n",
        "    while i <= j:\n",
        "        count += 1\n",
        "        if weight[i] + weight[j] <= 3:\n",
        "            i += 1\n",
        "        j -= 1\n",
        "    return count\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(efficientJanitor([1.01, 1.99, 2.5, 1.5, 1.01]))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew145VIECa-T"
      },
      "source": [
        "#### QB Q2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dciExlt5d5ac"
      },
      "source": [
        "#\n",
        "# Complete the 'encryptionValidity' function below.\n",
        "#\n",
        "# The function is expected to return an INTEGER_ARRAY.\n",
        "# The function accepts following parameters:\n",
        "#  1. INTEGER instructionCount\n",
        "#  2. INTEGER validityPeriod\n",
        "#  3. INTEGER_ARRAY keys\n",
        "#\n",
        "\n",
        "EXP = 10**5\n",
        "\n",
        "def encryptionValidity(instructionCount, validityPeriod, keys):\n",
        "    \"\"\"\n",
        "    Check if hijacker can crack code in validity period.\n",
        "\n",
        "    Args:\n",
        "      instuctionCount: number of keys that can be tried per s\n",
        "      validityPeriod: how long code is valid\n",
        "      keys: list of keys hijacker can test\n",
        "\n",
        "    Returns:\n",
        "      array consisting of:\n",
        "        can_solve: if code will be cracked by hijacker\n",
        "        strength: number of keys required to test to break encryption\n",
        "    \"\"\"\n",
        "    # Compute encryption strength\n",
        "    # Find num with most divisors\n",
        "    max_div = 1\n",
        "    for k in keys:\n",
        "        num_div = 0\n",
        "        for div in keys:\n",
        "            if k % div == 0:\n",
        "                num_div += 1\n",
        "        if num_div > max_div:\n",
        "            max_div = num_div\n",
        "  \n",
        "    strength = max_div * EXP\n",
        "    \n",
        "    # Check if solvable\n",
        "    can_test = instructionCount * validityPeriod\n",
        "    can_solve = int(can_test > strength)\n",
        "\n",
        "    return [can_solve, strength]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBYi4H57eFdm",
        "outputId": "8f4013b6-637e-4d84-8f9b-600d85ba4c95"
      },
      "source": [
        "encryptionValidity(1000, 10000, [2, 4, 8, 2])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 400000]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzoa-U1NCYNb"
      },
      "source": [
        "#### QB Q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x4OjHTCNjcAG",
        "outputId": "6778f2d3-5f52-4b98-e7cd-9042bb2dc047"
      },
      "source": [
        "!pip install lazypredict"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.9-py2.py3-none-any.whl (12 kB)\n",
            "Collecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.1\n",
            "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 31.8 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.56.0\n",
            "  Downloading tqdm-4.56.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from lazypredict) (7.1.2)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from lazypredict) (1.15.0)\n",
            "Collecting xgboost==1.1.1\n",
            "  Downloading xgboost-1.1.1-py3-none-manylinux2010_x86_64.whl (127.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 127.6 MB 22 kB/s \n",
            "\u001b[?25hCollecting lightgbm==2.3.1\n",
            "  Downloading lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 53.5 MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.3.1\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 54.0 MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.1\n",
            "  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 17 kB/s \n",
            "\u001b[?25hCollecting pandas==1.0.5\n",
            "  Downloading pandas-1.0.5-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 32.3 MB/s \n",
            "\u001b[?25hCollecting joblib==1.0.0\n",
            "  Downloading joblib-1.0.0-py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 51.8 MB/s \n",
            "\u001b[?25hCollecting pytest==5.4.3\n",
            "  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5->lazypredict) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.3->lazypredict) (21.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.3->lazypredict) (4.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.3->lazypredict) (21.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.3->lazypredict) (0.2.5)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.3->lazypredict) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.4.3->lazypredict) (8.9.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.4.3->lazypredict) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.4.3->lazypredict) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest==5.4.3->lazypredict) (2.4.7)\n",
            "Building wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44635 sha256=922effab17aab68ef5c82440551f5b5e6d87e4e09da8431db88d608f7fd4c6fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: numpy, threadpoolctl, scipy, joblib, scikit-learn, pluggy, xgboost, tqdm, PyYAML, pytest, pandas, lightgbm, lazypredict\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.2\n",
            "    Uninstalling tqdm-4.62.2:\n",
            "      Successfully uninstalled tqdm-4.62.2\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.19.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-5.3.1 joblib-1.0.0 lazypredict-0.2.9 lightgbm-2.3.1 numpy-1.19.1 pandas-1.0.5 pluggy-0.13.1 pytest-5.4.3 scikit-learn-0.23.1 scipy-1.5.4 threadpoolctl-2.2.0 tqdm-4.56.0 xgboost-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "numpy",
                  "pandas",
                  "scipy",
                  "sklearn",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ONzjshF0KDg"
      },
      "source": [
        "# dummy inputs (one day)\n",
        "data=[10.0,11.1,12.3,13.2,14.8,15.6,16.7,17.5,18.9,19.7,20.7,21.1,22.6,23.5,24.9,25.1,26.3,27.8,28.8,29.6,30.2,31.6,32.1,33.7,]\n",
        "startDate = '2013-01-01'\n",
        "endDate = '2013-01-01'\n",
        "p = 1\n",
        "n = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZIHrhVkjb8p"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "\n",
        "# TODO:\n",
        "# Choose better model by testing on more data\n",
        "# Improve feature encoding & possibly add additional features like temperature difference\n",
        "\n",
        "def train_model_cv(X, y, split=.67):\n",
        "    \"\"\"\n",
        "    Find the best model with simple cross validation of just 1 fold.\n",
        "    \"\"\"\n",
        "    X_train, X_test= np.split(X, [int(split *len(data))])\n",
        "    y_train, y_test= np.split(y, [int(split *len(data))])\n",
        "    reg = LazyRegressor(predictions=True)\n",
        "    models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
        "    return models\n",
        "\n",
        "def prepare_df(data):\n",
        "    \"\"\"Prepares time series DF for model input\"\"\"\n",
        "    df = pd.DataFrame(data)\n",
        "    # Prepare features for model input\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['hour'] = df['date'].dt.hour\n",
        "    return df\n",
        "\n",
        "\n",
        "def predictTemperature(startDate, endDate, temperature, n, debug=False):\n",
        "    \"\"\"\n",
        "    Forecast temperature for next n days based on historic temperature.\n",
        "\n",
        "    Args:\n",
        "      startDate: first day of temp data, yyyy-mm-dd\n",
        "      endDate: last day of temp data, yyyy-mm-dd\n",
        "      temperature: hourly float temp data points for date range\n",
        "      n: number of days of temperature to predict in the future\n",
        "\n",
        "    Returns:\n",
        "      temp: hourly float temp data for n future days, array of shape: [24 x n]\n",
        "\n",
        "    \"\"\"\n",
        "    num_days = int(len(temperature)/24)\n",
        "\n",
        "    start_date = pd.to_datetime(startDate)\n",
        "    end_date = pd.to_datetime(endDate) + pd.offsets.Day()\n",
        "    # Generate date range and cut off the last hour\n",
        "    date_range = pd.date_range(start_date, end_date, freq='H')[:-1]\n",
        "\n",
        "    data = {\"date\": date_range, \"temp\": temperature}\n",
        "    df = prepare_df(data)\n",
        "    \n",
        "    features = [\"month\", \"hour\"]\n",
        "\n",
        "    X = df[features].values\n",
        "    y = df[\"temp\"].values\n",
        "\n",
        "    # TODO: Use sinusoidal encoding for month & hour\n",
        "    enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc.fit(X)\n",
        "    X = enc.transform(X).toarray()\n",
        "\n",
        "    if debug:\n",
        "      model_df = train_model_cv(X, y)\n",
        "      return model_df\n",
        "\n",
        "    model = KernelRidge()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predict on future data\n",
        "    future_hours = n * 24\n",
        "    fin_date = df.iloc[-1].date + pd.DateOffset(hours=future_hours)\n",
        "    future_data = {\"date\": pd.date_range(df.iloc[-1].date, fin_date, freq='H')[:-1]}\n",
        "\n",
        "    df = prepare_df(future_data)\n",
        "    X = df[features].values\n",
        "    X = enc.transform(X).toarray()\n",
        "\n",
        "    return model.predict(X).tolist()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekwH3T0j0duM",
        "outputId": "99289bca-7634-489e-f21f-87067c018664"
      },
      "source": [
        "df = predictTemperature(startDate, endDate, data, n, debug=True)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [00:01<00:00, 26.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a_LafbNH0gNU",
        "outputId": "994643e0-13ae-4738-effe-dd2c16d2dd6e"
      },
      "source": [
        "df"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adjusted R-Squared</th>\n",
              "      <th>R-Squared</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KernelRidge</th>\n",
              "      <td>70.03</td>\n",
              "      <td>-176.49</td>\n",
              "      <td>30.10</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianProcessRegressor</th>\n",
              "      <td>69.87</td>\n",
              "      <td>-176.09</td>\n",
              "      <td>30.06</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPRegressor</th>\n",
              "      <td>46.64</td>\n",
              "      <td>-116.36</td>\n",
              "      <td>24.47</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsRegressor</th>\n",
              "      <td>25.35</td>\n",
              "      <td>-61.61</td>\n",
              "      <td>17.88</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVR</th>\n",
              "      <td>18.88</td>\n",
              "      <td>-44.99</td>\n",
              "      <td>15.32</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PoissonRegressor</th>\n",
              "      <td>13.52</td>\n",
              "      <td>-31.20</td>\n",
              "      <td>12.82</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GammaRegressor</th>\n",
              "      <td>13.35</td>\n",
              "      <td>-30.76</td>\n",
              "      <td>12.73</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDRegressor</th>\n",
              "      <td>12.75</td>\n",
              "      <td>-29.20</td>\n",
              "      <td>12.42</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVR</th>\n",
              "      <td>12.52</td>\n",
              "      <td>-28.63</td>\n",
              "      <td>12.30</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveRegressor</th>\n",
              "      <td>12.44</td>\n",
              "      <td>-28.42</td>\n",
              "      <td>12.25</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BayesianRidge</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLarsCV</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLars</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LarsCV</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoCV</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HistGradientBoostingRegressor</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GeneralizedLinearRegressor</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeCV</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNetCV</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyRegressor</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TweedieRegressor</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LassoLarsIC</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HuberRegressor</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMRegressor</th>\n",
              "      <td>12.42</td>\n",
              "      <td>-28.36</td>\n",
              "      <td>12.24</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNet</th>\n",
              "      <td>12.28</td>\n",
              "      <td>-28.00</td>\n",
              "      <td>12.17</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>12.16</td>\n",
              "      <td>-27.69</td>\n",
              "      <td>12.10</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostRegressor</th>\n",
              "      <td>12.14</td>\n",
              "      <td>-27.65</td>\n",
              "      <td>12.09</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVR</th>\n",
              "      <td>12.02</td>\n",
              "      <td>-27.34</td>\n",
              "      <td>12.03</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoostingRegressor</th>\n",
              "      <td>11.97</td>\n",
              "      <td>-27.21</td>\n",
              "      <td>12.00</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingRegressor</th>\n",
              "      <td>11.68</td>\n",
              "      <td>-26.47</td>\n",
              "      <td>11.84</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearRegression</th>\n",
              "      <td>11.54</td>\n",
              "      <td>-26.12</td>\n",
              "      <td>11.76</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TransformedTargetRegressor</th>\n",
              "      <td>11.54</td>\n",
              "      <td>-26.12</td>\n",
              "      <td>11.76</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OrthogonalMatchingPursuitCV</th>\n",
              "      <td>11.46</td>\n",
              "      <td>-25.91</td>\n",
              "      <td>11.72</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lars</th>\n",
              "      <td>10.80</td>\n",
              "      <td>-24.20</td>\n",
              "      <td>11.34</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor</th>\n",
              "      <td>10.58</td>\n",
              "      <td>-23.63</td>\n",
              "      <td>11.21</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OrthogonalMatchingPursuit</th>\n",
              "      <td>10.56</td>\n",
              "      <td>-23.58</td>\n",
              "      <td>11.20</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBRegressor</th>\n",
              "      <td>7.93</td>\n",
              "      <td>-16.81</td>\n",
              "      <td>9.53</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeRegressor</th>\n",
              "      <td>3.38</td>\n",
              "      <td>-5.12</td>\n",
              "      <td>5.59</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesRegressor</th>\n",
              "      <td>3.31</td>\n",
              "      <td>-4.93</td>\n",
              "      <td>5.50</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeRegressor</th>\n",
              "      <td>3.23</td>\n",
              "      <td>-4.73</td>\n",
              "      <td>5.41</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
              "Model                                                                         \n",
              "KernelRidge                                 70.03    -176.49 30.10        0.01\n",
              "GaussianProcessRegressor                    69.87    -176.09 30.06        0.01\n",
              "MLPRegressor                                46.64    -116.36 24.47        0.12\n",
              "KNeighborsRegressor                         25.35     -61.61 17.88        0.02\n",
              "LinearSVR                                   18.88     -44.99 15.32        0.01\n",
              "PoissonRegressor                            13.52     -31.20 12.82        0.01\n",
              "GammaRegressor                              13.35     -30.76 12.73        0.01\n",
              "SGDRegressor                                12.75     -29.20 12.42        0.01\n",
              "NuSVR                                       12.52     -28.63 12.30        0.01\n",
              "PassiveAggressiveRegressor                  12.44     -28.42 12.25        0.01\n",
              "BayesianRidge                               12.42     -28.36 12.24        0.01\n",
              "LassoLarsCV                                 12.42     -28.36 12.24        0.03\n",
              "LassoLars                                   12.42     -28.36 12.24        0.02\n",
              "LarsCV                                      12.42     -28.36 12.24        0.03\n",
              "LassoCV                                     12.42     -28.36 12.24        0.05\n",
              "HistGradientBoostingRegressor               12.42     -28.36 12.24        0.03\n",
              "GeneralizedLinearRegressor                  12.42     -28.36 12.24        0.01\n",
              "Ridge                                       12.42     -28.36 12.24        0.01\n",
              "RidgeCV                                     12.42     -28.36 12.24        0.01\n",
              "ElasticNetCV                                12.42     -28.36 12.24        0.04\n",
              "DummyRegressor                              12.42     -28.36 12.24        0.01\n",
              "TweedieRegressor                            12.42     -28.36 12.24        0.01\n",
              "LassoLarsIC                                 12.42     -28.36 12.24        0.02\n",
              "HuberRegressor                              12.42     -28.36 12.24        0.04\n",
              "LGBMRegressor                               12.42     -28.36 12.24        0.03\n",
              "ElasticNet                                  12.28     -28.00 12.17        0.01\n",
              "Lasso                                       12.16     -27.69 12.10        0.01\n",
              "AdaBoostRegressor                           12.14     -27.65 12.09        0.07\n",
              "SVR                                         12.02     -27.34 12.03        0.01\n",
              "GradientBoostingRegressor                   11.97     -27.21 12.00        0.03\n",
              "BaggingRegressor                            11.68     -26.47 11.84        0.03\n",
              "LinearRegression                            11.54     -26.12 11.76        0.01\n",
              "TransformedTargetRegressor                  11.54     -26.12 11.76        0.01\n",
              "OrthogonalMatchingPursuitCV                 11.46     -25.91 11.72        0.02\n",
              "Lars                                        10.80     -24.20 11.34        0.01\n",
              "RandomForestRegressor                       10.58     -23.63 11.21        0.17\n",
              "OrthogonalMatchingPursuit                   10.56     -23.58 11.20        0.01\n",
              "XGBRegressor                                 7.93     -16.81  9.53        0.40\n",
              "ExtraTreeRegressor                           3.38      -5.12  5.59        0.01\n",
              "ExtraTreesRegressor                          3.31      -4.93  5.50        0.12\n",
              "DecisionTreeRegressor                        3.23      -4.73  5.41        0.01"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFi_o_SulKhW"
      },
      "source": [
        "# necessary import libraries\n",
        "import numpy as np\n",
        "import datetime,time\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# dummy inputs (one day)\n",
        "data=[10.0,11.1,12.3,13.2,14.8,15.6,16.7,17.5,18.9,19.7,20.7,21.1,22.6,23.5,24.9,25.1,26.3,27.8,28.8,29.6,30.2,31.6,32.1,33.7,]\n",
        "startDate = '2013-01-01'\n",
        "endDate = '2013-01-01'\n",
        "p = 1\n",
        "n = 1\n",
        "\n",
        "# utility function\n",
        "def predictTemperature(startDate, endDate, temperature, n):\n",
        "\n",
        "    p = int(len(temperature)/24)\n",
        "    x = []\n",
        "    for i in range(1,((24*p)+1)):\n",
        "        x.append(i)\n",
        "    y = temperature\n",
        "    lm = LinearRegression()\n",
        "    lm.fit(np.asarray(x).reshape(-1,1),y)\n",
        "\n",
        "    print(x)\n",
        "    \n",
        "    f = x[-1]+1\n",
        "    z = []\n",
        "    for i in range(24*n):\n",
        "        z.append(f)\n",
        "        f += 1\n",
        "    return(lm.predict(np.asarray(z).reshape(-1,1)).tolist())"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr1p_TLulK0T",
        "outputId": "cc499917-f65f-4c69-9a0a-abcfc25fb369"
      },
      "source": [
        "print(predictTemperature(startDate, endDate, data, n))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "[34.57862318840579, 35.58557971014493, 36.592536231884054, 37.59949275362318, 38.60644927536231, 39.61340579710144, 40.62036231884058, 41.627318840579704, 42.63427536231883, 43.641231884057966, 44.64818840579709, 45.65514492753623, 46.662101449275355, 47.66905797101449, 48.676014492753616, 49.68297101449275, 50.68992753623188, 51.696884057971005, 52.70384057971014, 53.710797101449266, 54.7177536231884, 55.72471014492753, 56.73166666666666, 57.73862318840579]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGNQs3PVnHR6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}